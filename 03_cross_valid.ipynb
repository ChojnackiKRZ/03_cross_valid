{"cells":[{"cell_type":"code","source":["from sklearn.datasets import load_iris, load_diabetes,load_wine\nfrom sklearn.dummy import DummyClassifier\nfrom sklearn.linear_model import LinearRegression, Ridge\nfrom sklearn.metrics import r2_score,mean_squared_error\nfrom sklearn import linear_model\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import KFold, StratifiedKFold,cross_val_score\nimport numpy as np\nfrom matplotlib import pyplot as plt\nfrom sklearn.neighbors import KNeighborsClassifier\nimport pandas as pd\nfrom statistics import mean"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"732b8975-a8ec-4962-a67c-9f705401e24d"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["wine = load_wine()\n\n#Kfold\nfeatures, target = wine.data, wine.target\n\navg_score = []\n\nkf = KFold(n_splits=3)\nkf.get_n_splits(features)\nknn = KNeighborsClassifier(n_neighbors=3)\n\nprint(kf)\n\nfor train_index, test_index in kf.split(features):\n    print(\"\\ntrain_size:\", len(train_index),\"\\n\" ,\"\\ntest_size\", len(test_index),\"\\n\")\n    X_train, X_test = features[train_index], features[test_index]\n    y_train, y_test = target[train_index], target[test_index]\n    \n    print(\"\\ntest_class_size:\\n\",pd.value_counts(y_test))\n    print(\"\\ntrain_class_size:\\n\",pd.value_counts(y_train))\n    \n    knn.fit(X_train,y_train)\n\n    score_fold_value = knn.score(X_test,y_test)\n\n    print(\"score:\",score_fold_value)\n    avg_score.append(score_fold_value)\n    print(50*\"*\")\n    \nprint(\"avg_mean: \", mean(avg_score))\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0103658b-9565-4091-a53d-817f5f7de8f3"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"KFold(n_splits=3, random_state=None, shuffle=False)\n\ntrain_size: 118 \n \ntest_size 60 \n\n\ntest_class_size:\n 0    59\n1     1\ndtype: int64\n\ntrain_class_size:\n 1    70\n2    48\ndtype: int64\nscore: 0.0\n**************************************************\n\ntrain_size: 119 \n \ntest_size 59 \n\n\ntest_class_size:\n 1    59\ndtype: int64\n\ntrain_class_size:\n 0    59\n2    48\n1    12\ndtype: int64\nscore: 0.288135593220339\n**************************************************\n\ntrain_size: 119 \n \ntest_size 59 \n\n\ntest_class_size:\n 2    48\n1    11\ndtype: int64\n\ntrain_class_size:\n 1    60\n0    59\ndtype: int64\nscore: 0.1864406779661017\n**************************************************\navg_mean:  0.15819209039548024\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["KFold(n_splits=3, random_state=None, shuffle=False)\n\ntrain_size: 118 \n \ntest_size 60 \n\n\ntest_class_size:\n 0    59\n1     1\ndtype: int64\n\ntrain_class_size:\n 1    70\n2    48\ndtype: int64\nscore: 0.0\n**************************************************\n\ntrain_size: 119 \n \ntest_size 59 \n\n\ntest_class_size:\n 1    59\ndtype: int64\n\ntrain_class_size:\n 0    59\n2    48\n1    12\ndtype: int64\nscore: 0.288135593220339\n**************************************************\n\ntrain_size: 119 \n \ntest_size 59 \n\n\ntest_class_size:\n 2    48\n1    11\ndtype: int64\n\ntrain_class_size:\n 1    60\n0    59\ndtype: int64\nscore: 0.1864406779661017\n**************************************************\navg_mean:  0.15819209039548024\n"]}}],"execution_count":0},{"cell_type":"code","source":["#StratifiedKFold\n\navg_score = []\nfeatures, target = wine.data, wine.target\n\nskf = StratifiedKFold(n_splits=3)\nskf.get_n_splits(features,target)\nknn = KNeighborsClassifier(n_neighbors=3)\n\nprint(skf)\n\nfor train_index, test_index in skf.split(features,target):\n    print(\"\\ntrain_size:\", len(train_index),\"\\n\" ,\"\\ntest_size\", len(test_index),\"\\n\")\n    X_train, X_test = features[train_index], features[test_index]\n    y_train, y_test = target[train_index], target[test_index]\n    \n    print(\"\\ntest_class_size:\\n\",pd.value_counts(y_test))\n    print(\"\\ntrain_class_size:\\n\",pd.value_counts(y_train))\n    \n    knn.fit(X_train,y_train)\n    \n    score_fold_value = knn.score(X_test,y_test)\n\n    print(\"score:\",score_fold_value)\n    avg_score.append(score_fold_value)\n    print(50*\"*\")\n    \nprint(\"avg_mean: \", mean(avg_score))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4fe0037a-bc36-4720-8713-b0e6e818e4d0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"StratifiedKFold(n_splits=3, random_state=None, shuffle=False)\n\ntrain_size: 118 \n \ntest_size 60 \n\n\ntest_class_size:\n 1    24\n0    20\n2    16\ndtype: int64\n\ntrain_class_size:\n 1    47\n0    39\n2    32\ndtype: int64\nscore: 0.6166666666666667\n**************************************************\n\ntrain_size: 119 \n \ntest_size 59 \n\n\ntest_class_size:\n 1    23\n0    20\n2    16\ndtype: int64\n\ntrain_class_size:\n 1    48\n0    39\n2    32\ndtype: int64\nscore: 0.576271186440678\n**************************************************\n\ntrain_size: 119 \n \ntest_size 59 \n\n\ntest_class_size:\n 1    24\n0    19\n2    16\ndtype: int64\n\ntrain_class_size:\n 1    47\n0    40\n2    32\ndtype: int64\nscore: 0.7966101694915254\n**************************************************\navg_mean:  0.6631826741996234\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["StratifiedKFold(n_splits=3, random_state=None, shuffle=False)\n\ntrain_size: 118 \n \ntest_size 60 \n\n\ntest_class_size:\n 1    24\n0    20\n2    16\ndtype: int64\n\ntrain_class_size:\n 1    47\n0    39\n2    32\ndtype: int64\nscore: 0.6166666666666667\n**************************************************\n\ntrain_size: 119 \n \ntest_size 59 \n\n\ntest_class_size:\n 1    23\n0    20\n2    16\ndtype: int64\n\ntrain_class_size:\n 1    48\n0    39\n2    32\ndtype: int64\nscore: 0.576271186440678\n**************************************************\n\ntrain_size: 119 \n \ntest_size 59 \n\n\ntest_class_size:\n 1    24\n0    19\n2    16\ndtype: int64\n\ntrain_class_size:\n 1    47\n0    40\n2    32\ndtype: int64\nscore: 0.7966101694915254\n**************************************************\navg_mean:  0.6631826741996234\n"]}}],"execution_count":0},{"cell_type":"code","source":["knn = KNeighborsClassifier(n_neighbors=3)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4d5c8766-4ced-432d-8ff5-2e03ec42c1b0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"[0.61666667 0.57627119 0.79661017]\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["[0.61666667 0.57627119 0.79661017]\n"]}}],"execution_count":0},{"cell_type":"code","source":["%time print(cross_val_score(knn, features, target, cv=3, verbose=1))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1cdfc55b-c939-4643-bf0d-d0c02c56c211"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"[0.61666667 0.57627119 0.79661017]\nWall time: 28 ms\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["[0.61666667 0.57627119 0.79661017]\nWall time: 28 ms\n"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n"]}}],"execution_count":0},{"cell_type":"code","source":["%time print(cross_val_score(knn, features, target, cv=5,verbose=5))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"378caf0f-3308-4107-b36d-ff73ef32ca2f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"[CV] END ................................ score: (test=0.639) total time=   0.0s\n[CV] END ................................ score: (test=0.694) total time=   0.0s\n[CV] END ................................ score: (test=0.667) total time=   0.0s\n[CV] END ................................ score: (test=0.657) total time=   0.0s\n[CV] END ................................ score: (test=0.857) total time=   0.0s\n[0.63888889 0.69444444 0.66666667 0.65714286 0.85714286]\nWall time: 37 ms\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["[CV] END ................................ score: (test=0.639) total time=   0.0s\n[CV] END ................................ score: (test=0.694) total time=   0.0s\n[CV] END ................................ score: (test=0.667) total time=   0.0s\n[CV] END ................................ score: (test=0.657) total time=   0.0s\n[CV] END ................................ score: (test=0.857) total time=   0.0s\n[0.63888889 0.69444444 0.66666667 0.65714286 0.85714286]\nWall time: 37 ms\n"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n"]}}],"execution_count":0},{"cell_type":"code","source":["%time print(cross_val_score(knn, features, target, cv=10))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6f5941e2-9844-41b9-a9cd-5813bbf7ea8e"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["X_test"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"968b2e2d-1268-429f-b81f-c5d445fa7378"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[93]: array([[1.423e+01, 1.710e+00, 2.430e+00, 1.560e+01, 1.270e+02, 2.800e+00,\n        3.060e+00, 2.800e-01, 2.290e+00, 5.640e+00, 1.040e+00, 3.920e+00,\n        1.065e+03],\n       [1.320e+01, 1.780e+00, 2.140e+00, 1.120e+01, 1.000e+02, 2.650e+00,\n        2.760e+00, 2.600e-01, 1.280e+00, 4.380e+00, 1.050e+00, 3.400e+00,\n        1.050e+03],\n       [1.316e+01, 2.360e+00, 2.670e+00, 1.860e+01, 1.010e+02, 2.800e+00,\n        3.240e+00, 3.000e-01, 2.810e+00, 5.680e+00, 1.030e+00, 3.170e+00,\n        1.185e+03],\n       [1.437e+01, 1.950e+00, 2.500e+00, 1.680e+01, 1.130e+02, 3.850e+00,\n        3.490e+00, 2.400e-01, 2.180e+00, 7.800e+00, 8.600e-01, 3.450e+00,\n        1.480e+03],\n       [1.324e+01, 2.590e+00, 2.870e+00, 2.100e+01, 1.180e+02, 2.800e+00,\n        2.690e+00, 3.900e-01, 1.820e+00, 4.320e+00, 1.040e+00, 2.930e+00,\n        7.350e+02],\n       [1.420e+01, 1.760e+00, 2.450e+00, 1.520e+01, 1.120e+02, 3.270e+00,\n        3.390e+00, 3.400e-01, 1.970e+00, 6.750e+00, 1.050e+00, 2.850e+00,\n        1.450e+03],\n       [1.439e+01, 1.870e+00, 2.450e+00, 1.460e+01, 9.600e+01, 2.500e+00,\n        2.520e+00, 3.000e-01, 1.980e+00, 5.250e+00, 1.020e+00, 3.580e+00,\n        1.290e+03],\n       [1.406e+01, 2.150e+00, 2.610e+00, 1.760e+01, 1.210e+02, 2.600e+00,\n        2.510e+00, 3.100e-01, 1.250e+00, 5.050e+00, 1.060e+00, 3.580e+00,\n        1.295e+03],\n       [1.483e+01, 1.640e+00, 2.170e+00, 1.400e+01, 9.700e+01, 2.800e+00,\n        2.980e+00, 2.900e-01, 1.980e+00, 5.200e+00, 1.080e+00, 2.850e+00,\n        1.045e+03],\n       [1.386e+01, 1.350e+00, 2.270e+00, 1.600e+01, 9.800e+01, 2.980e+00,\n        3.150e+00, 2.200e-01, 1.850e+00, 7.220e+00, 1.010e+00, 3.550e+00,\n        1.045e+03],\n       [1.410e+01, 2.160e+00, 2.300e+00, 1.800e+01, 1.050e+02, 2.950e+00,\n        3.320e+00, 2.200e-01, 2.380e+00, 5.750e+00, 1.250e+00, 3.170e+00,\n        1.510e+03],\n       [1.412e+01, 1.480e+00, 2.320e+00, 1.680e+01, 9.500e+01, 2.200e+00,\n        2.430e+00, 2.600e-01, 1.570e+00, 5.000e+00, 1.170e+00, 2.820e+00,\n        1.280e+03],\n       [1.375e+01, 1.730e+00, 2.410e+00, 1.600e+01, 8.900e+01, 2.600e+00,\n        2.760e+00, 2.900e-01, 1.810e+00, 5.600e+00, 1.150e+00, 2.900e+00,\n        1.320e+03],\n       [1.475e+01, 1.730e+00, 2.390e+00, 1.140e+01, 9.100e+01, 3.100e+00,\n        3.690e+00, 4.300e-01, 2.810e+00, 5.400e+00, 1.250e+00, 2.730e+00,\n        1.150e+03],\n       [1.438e+01, 1.870e+00, 2.380e+00, 1.200e+01, 1.020e+02, 3.300e+00,\n        3.640e+00, 2.900e-01, 2.960e+00, 7.500e+00, 1.200e+00, 3.000e+00,\n        1.547e+03],\n       [1.363e+01, 1.810e+00, 2.700e+00, 1.720e+01, 1.120e+02, 2.850e+00,\n        2.910e+00, 3.000e-01, 1.460e+00, 7.300e+00, 1.280e+00, 2.880e+00,\n        1.310e+03],\n       [1.430e+01, 1.920e+00, 2.720e+00, 2.000e+01, 1.200e+02, 2.800e+00,\n        3.140e+00, 3.300e-01, 1.970e+00, 6.200e+00, 1.070e+00, 2.650e+00,\n        1.280e+03],\n       [1.383e+01, 1.570e+00, 2.620e+00, 2.000e+01, 1.150e+02, 2.950e+00,\n        3.400e+00, 4.000e-01, 1.720e+00, 6.600e+00, 1.130e+00, 2.570e+00,\n        1.130e+03],\n       [1.419e+01, 1.590e+00, 2.480e+00, 1.650e+01, 1.080e+02, 3.300e+00,\n        3.930e+00, 3.200e-01, 1.860e+00, 8.700e+00, 1.230e+00, 2.820e+00,\n        1.680e+03],\n       [1.364e+01, 3.100e+00, 2.560e+00, 1.520e+01, 1.160e+02, 2.700e+00,\n        3.030e+00, 1.700e-01, 1.660e+00, 5.100e+00, 9.600e-01, 3.360e+00,\n        8.450e+02],\n       [1.406e+01, 1.630e+00, 2.280e+00, 1.600e+01, 1.260e+02, 3.000e+00,\n        3.170e+00, 2.400e-01, 2.100e+00, 5.650e+00, 1.090e+00, 3.710e+00,\n        7.800e+02],\n       [1.293e+01, 3.800e+00, 2.650e+00, 1.860e+01, 1.020e+02, 2.410e+00,\n        2.410e+00, 2.500e-01, 1.980e+00, 4.500e+00, 1.030e+00, 3.520e+00,\n        7.700e+02],\n       [1.371e+01, 1.860e+00, 2.360e+00, 1.660e+01, 1.010e+02, 2.610e+00,\n        2.880e+00, 2.700e-01, 1.690e+00, 3.800e+00, 1.110e+00, 4.000e+00,\n        1.035e+03],\n       [1.285e+01, 1.600e+00, 2.520e+00, 1.780e+01, 9.500e+01, 2.480e+00,\n        2.370e+00, 2.600e-01, 1.460e+00, 3.930e+00, 1.090e+00, 3.630e+00,\n        1.015e+03],\n       [1.350e+01, 1.810e+00, 2.610e+00, 2.000e+01, 9.600e+01, 2.530e+00,\n        2.610e+00, 2.800e-01, 1.660e+00, 3.520e+00, 1.120e+00, 3.820e+00,\n        8.450e+02],\n       [1.305e+01, 2.050e+00, 3.220e+00, 2.500e+01, 1.240e+02, 2.630e+00,\n        2.680e+00, 4.700e-01, 1.920e+00, 3.580e+00, 1.130e+00, 3.200e+00,\n        8.300e+02],\n       [1.339e+01, 1.770e+00, 2.620e+00, 1.610e+01, 9.300e+01, 2.850e+00,\n        2.940e+00, 3.400e-01, 1.450e+00, 4.800e+00, 9.200e-01, 3.220e+00,\n        1.195e+03],\n       [1.330e+01, 1.720e+00, 2.140e+00, 1.700e+01, 9.400e+01, 2.400e+00,\n        2.190e+00, 2.700e-01, 1.350e+00, 3.950e+00, 1.020e+00, 2.770e+00,\n        1.285e+03],\n       [1.387e+01, 1.900e+00, 2.800e+00, 1.940e+01, 1.070e+02, 2.950e+00,\n        2.970e+00, 3.700e-01, 1.760e+00, 4.500e+00, 1.250e+00, 3.400e+00,\n        9.150e+02],\n       [1.402e+01, 1.680e+00, 2.210e+00, 1.600e+01, 9.600e+01, 2.650e+00,\n        2.330e+00, 2.600e-01, 1.980e+00, 4.700e+00, 1.040e+00, 3.590e+00,\n        1.035e+03],\n       [1.373e+01, 1.500e+00, 2.700e+00, 2.250e+01, 1.010e+02, 3.000e+00,\n        3.250e+00, 2.900e-01, 2.380e+00, 5.700e+00, 1.190e+00, 2.710e+00,\n        1.285e+03],\n       [1.358e+01, 1.660e+00, 2.360e+00, 1.910e+01, 1.060e+02, 2.860e+00,\n        3.190e+00, 2.200e-01, 1.950e+00, 6.900e+00, 1.090e+00, 2.880e+00,\n        1.515e+03],\n       [1.368e+01, 1.830e+00, 2.360e+00, 1.720e+01, 1.040e+02, 2.420e+00,\n        2.690e+00, 4.200e-01, 1.970e+00, 3.840e+00, 1.230e+00, 2.870e+00,\n        9.900e+02],\n       [1.376e+01, 1.530e+00, 2.700e+00, 1.950e+01, 1.320e+02, 2.950e+00,\n        2.740e+00, 5.000e-01, 1.350e+00, 5.400e+00, 1.250e+00, 3.000e+00,\n        1.235e+03],\n       [1.351e+01, 1.800e+00, 2.650e+00, 1.900e+01, 1.100e+02, 2.350e+00,\n        2.530e+00, 2.900e-01, 1.540e+00, 4.200e+00, 1.100e+00, 2.870e+00,\n        1.095e+03],\n       [1.348e+01, 1.810e+00, 2.410e+00, 2.050e+01, 1.000e+02, 2.700e+00,\n        2.980e+00, 2.600e-01, 1.860e+00, 5.100e+00, 1.040e+00, 3.470e+00,\n        9.200e+02],\n       [1.328e+01, 1.640e+00, 2.840e+00, 1.550e+01, 1.100e+02, 2.600e+00,\n        2.680e+00, 3.400e-01, 1.360e+00, 4.600e+00, 1.090e+00, 2.780e+00,\n        8.800e+02],\n       [1.305e+01, 1.650e+00, 2.550e+00, 1.800e+01, 9.800e+01, 2.450e+00,\n        2.430e+00, 2.900e-01, 1.440e+00, 4.250e+00, 1.120e+00, 2.510e+00,\n        1.105e+03],\n       [1.307e+01, 1.500e+00, 2.100e+00, 1.550e+01, 9.800e+01, 2.400e+00,\n        2.640e+00, 2.800e-01, 1.370e+00, 3.700e+00, 1.180e+00, 2.690e+00,\n        1.020e+03],\n       [1.422e+01, 3.990e+00, 2.510e+00, 1.320e+01, 1.280e+02, 3.000e+00,\n        3.040e+00, 2.000e-01, 2.080e+00, 5.100e+00, 8.900e-01, 3.530e+00,\n        7.600e+02],\n       [1.356e+01, 1.710e+00, 2.310e+00, 1.620e+01, 1.170e+02, 3.150e+00,\n        3.290e+00, 3.400e-01, 2.340e+00, 6.130e+00, 9.500e-01, 3.380e+00,\n        7.950e+02],\n       [1.341e+01, 3.840e+00, 2.120e+00, 1.880e+01, 9.000e+01, 2.450e+00,\n        2.680e+00, 2.700e-01, 1.480e+00, 4.280e+00, 9.100e-01, 3.000e+00,\n        1.035e+03],\n       [1.388e+01, 1.890e+00, 2.590e+00, 1.500e+01, 1.010e+02, 3.250e+00,\n        3.560e+00, 1.700e-01, 1.700e+00, 5.430e+00, 8.800e-01, 3.560e+00,\n        1.095e+03],\n       [1.324e+01, 3.980e+00, 2.290e+00, 1.750e+01, 1.030e+02, 2.640e+00,\n        2.630e+00, 3.200e-01, 1.660e+00, 4.360e+00, 8.200e-01, 3.000e+00,\n        6.800e+02],\n       [1.305e+01, 1.770e+00, 2.100e+00, 1.700e+01, 1.070e+02, 3.000e+00,\n        3.000e+00, 2.800e-01, 2.030e+00, 5.040e+00, 8.800e-01, 3.350e+00,\n        8.850e+02],\n       [1.421e+01, 4.040e+00, 2.440e+00, 1.890e+01, 1.110e+02, 2.850e+00,\n        2.650e+00, 3.000e-01, 1.250e+00, 5.240e+00, 8.700e-01, 3.330e+00,\n        1.080e+03],\n       [1.438e+01, 3.590e+00, 2.280e+00, 1.600e+01, 1.020e+02, 3.250e+00,\n        3.170e+00, 2.700e-01, 2.190e+00, 4.900e+00, 1.040e+00, 3.440e+00,\n        1.065e+03],\n       [1.390e+01, 1.680e+00, 2.120e+00, 1.600e+01, 1.010e+02, 3.100e+00,\n        3.390e+00, 2.100e-01, 2.140e+00, 6.100e+00, 9.100e-01, 3.330e+00,\n        9.850e+02],\n       [1.410e+01, 2.020e+00, 2.400e+00, 1.880e+01, 1.030e+02, 2.750e+00,\n        2.920e+00, 3.200e-01, 2.380e+00, 6.200e+00, 1.070e+00, 2.750e+00,\n        1.060e+03],\n       [1.394e+01, 1.730e+00, 2.270e+00, 1.740e+01, 1.080e+02, 2.880e+00,\n        3.540e+00, 3.200e-01, 2.080e+00, 8.900e+00, 1.120e+00, 3.100e+00,\n        1.260e+03],\n       [1.305e+01, 1.730e+00, 2.040e+00, 1.240e+01, 9.200e+01, 2.720e+00,\n        3.270e+00, 1.700e-01, 2.910e+00, 7.200e+00, 1.120e+00, 2.910e+00,\n        1.150e+03],\n       [1.383e+01, 1.650e+00, 2.600e+00, 1.720e+01, 9.400e+01, 2.450e+00,\n        2.990e+00, 2.200e-01, 2.290e+00, 5.600e+00, 1.240e+00, 3.370e+00,\n        1.265e+03],\n       [1.382e+01, 1.750e+00, 2.420e+00, 1.400e+01, 1.110e+02, 3.880e+00,\n        3.740e+00, 3.200e-01, 1.870e+00, 7.050e+00, 1.010e+00, 3.260e+00,\n        1.190e+03],\n       [1.377e+01, 1.900e+00, 2.680e+00, 1.710e+01, 1.150e+02, 3.000e+00,\n        2.790e+00, 3.900e-01, 1.680e+00, 6.300e+00, 1.130e+00, 2.930e+00,\n        1.375e+03],\n       [1.374e+01, 1.670e+00, 2.250e+00, 1.640e+01, 1.180e+02, 2.600e+00,\n        2.900e+00, 2.100e-01, 1.620e+00, 5.850e+00, 9.200e-01, 3.200e+00,\n        1.060e+03],\n       [1.356e+01, 1.730e+00, 2.460e+00, 2.050e+01, 1.160e+02, 2.960e+00,\n        2.780e+00, 2.000e-01, 2.450e+00, 6.250e+00, 9.800e-01, 3.030e+00,\n        1.120e+03],\n       [1.422e+01, 1.700e+00, 2.300e+00, 1.630e+01, 1.180e+02, 3.200e+00,\n        3.000e+00, 2.600e-01, 2.030e+00, 6.380e+00, 9.400e-01, 3.310e+00,\n        9.700e+02],\n       [1.329e+01, 1.970e+00, 2.680e+00, 1.680e+01, 1.020e+02, 3.000e+00,\n        3.230e+00, 3.100e-01, 1.660e+00, 6.000e+00, 1.070e+00, 2.840e+00,\n        1.270e+03],\n       [1.372e+01, 1.430e+00, 2.500e+00, 1.670e+01, 1.080e+02, 3.400e+00,\n        3.670e+00, 1.900e-01, 2.040e+00, 6.800e+00, 8.900e-01, 2.870e+00,\n        1.285e+03],\n       [1.237e+01, 9.400e-01, 1.360e+00, 1.060e+01, 8.800e+01, 1.980e+00,\n        5.700e-01, 2.800e-01, 4.200e-01, 1.950e+00, 1.050e+00, 1.820e+00,\n        5.200e+02]])","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[93]: array([[1.423e+01, 1.710e+00, 2.430e+00, 1.560e+01, 1.270e+02, 2.800e+00,\n        3.060e+00, 2.800e-01, 2.290e+00, 5.640e+00, 1.040e+00, 3.920e+00,\n        1.065e+03],\n       [1.320e+01, 1.780e+00, 2.140e+00, 1.120e+01, 1.000e+02, 2.650e+00,\n        2.760e+00, 2.600e-01, 1.280e+00, 4.380e+00, 1.050e+00, 3.400e+00,\n        1.050e+03],\n       [1.316e+01, 2.360e+00, 2.670e+00, 1.860e+01, 1.010e+02, 2.800e+00,\n        3.240e+00, 3.000e-01, 2.810e+00, 5.680e+00, 1.030e+00, 3.170e+00,\n        1.185e+03],\n       [1.437e+01, 1.950e+00, 2.500e+00, 1.680e+01, 1.130e+02, 3.850e+00,\n        3.490e+00, 2.400e-01, 2.180e+00, 7.800e+00, 8.600e-01, 3.450e+00,\n        1.480e+03],\n       [1.324e+01, 2.590e+00, 2.870e+00, 2.100e+01, 1.180e+02, 2.800e+00,\n        2.690e+00, 3.900e-01, 1.820e+00, 4.320e+00, 1.040e+00, 2.930e+00,\n        7.350e+02],\n       [1.420e+01, 1.760e+00, 2.450e+00, 1.520e+01, 1.120e+02, 3.270e+00,\n        3.390e+00, 3.400e-01, 1.970e+00, 6.750e+00, 1.050e+00, 2.850e+00,\n        1.450e+03],\n       [1.439e+01, 1.870e+00, 2.450e+00, 1.460e+01, 9.600e+01, 2.500e+00,\n        2.520e+00, 3.000e-01, 1.980e+00, 5.250e+00, 1.020e+00, 3.580e+00,\n        1.290e+03],\n       [1.406e+01, 2.150e+00, 2.610e+00, 1.760e+01, 1.210e+02, 2.600e+00,\n        2.510e+00, 3.100e-01, 1.250e+00, 5.050e+00, 1.060e+00, 3.580e+00,\n        1.295e+03],\n       [1.483e+01, 1.640e+00, 2.170e+00, 1.400e+01, 9.700e+01, 2.800e+00,\n        2.980e+00, 2.900e-01, 1.980e+00, 5.200e+00, 1.080e+00, 2.850e+00,\n        1.045e+03],\n       [1.386e+01, 1.350e+00, 2.270e+00, 1.600e+01, 9.800e+01, 2.980e+00,\n        3.150e+00, 2.200e-01, 1.850e+00, 7.220e+00, 1.010e+00, 3.550e+00,\n        1.045e+03],\n       [1.410e+01, 2.160e+00, 2.300e+00, 1.800e+01, 1.050e+02, 2.950e+00,\n        3.320e+00, 2.200e-01, 2.380e+00, 5.750e+00, 1.250e+00, 3.170e+00,\n        1.510e+03],\n       [1.412e+01, 1.480e+00, 2.320e+00, 1.680e+01, 9.500e+01, 2.200e+00,\n        2.430e+00, 2.600e-01, 1.570e+00, 5.000e+00, 1.170e+00, 2.820e+00,\n        1.280e+03],\n       [1.375e+01, 1.730e+00, 2.410e+00, 1.600e+01, 8.900e+01, 2.600e+00,\n        2.760e+00, 2.900e-01, 1.810e+00, 5.600e+00, 1.150e+00, 2.900e+00,\n        1.320e+03],\n       [1.475e+01, 1.730e+00, 2.390e+00, 1.140e+01, 9.100e+01, 3.100e+00,\n        3.690e+00, 4.300e-01, 2.810e+00, 5.400e+00, 1.250e+00, 2.730e+00,\n        1.150e+03],\n       [1.438e+01, 1.870e+00, 2.380e+00, 1.200e+01, 1.020e+02, 3.300e+00,\n        3.640e+00, 2.900e-01, 2.960e+00, 7.500e+00, 1.200e+00, 3.000e+00,\n        1.547e+03],\n       [1.363e+01, 1.810e+00, 2.700e+00, 1.720e+01, 1.120e+02, 2.850e+00,\n        2.910e+00, 3.000e-01, 1.460e+00, 7.300e+00, 1.280e+00, 2.880e+00,\n        1.310e+03],\n       [1.430e+01, 1.920e+00, 2.720e+00, 2.000e+01, 1.200e+02, 2.800e+00,\n        3.140e+00, 3.300e-01, 1.970e+00, 6.200e+00, 1.070e+00, 2.650e+00,\n        1.280e+03],\n       [1.383e+01, 1.570e+00, 2.620e+00, 2.000e+01, 1.150e+02, 2.950e+00,\n        3.400e+00, 4.000e-01, 1.720e+00, 6.600e+00, 1.130e+00, 2.570e+00,\n        1.130e+03],\n       [1.419e+01, 1.590e+00, 2.480e+00, 1.650e+01, 1.080e+02, 3.300e+00,\n        3.930e+00, 3.200e-01, 1.860e+00, 8.700e+00, 1.230e+00, 2.820e+00,\n        1.680e+03],\n       [1.364e+01, 3.100e+00, 2.560e+00, 1.520e+01, 1.160e+02, 2.700e+00,\n        3.030e+00, 1.700e-01, 1.660e+00, 5.100e+00, 9.600e-01, 3.360e+00,\n        8.450e+02],\n       [1.406e+01, 1.630e+00, 2.280e+00, 1.600e+01, 1.260e+02, 3.000e+00,\n        3.170e+00, 2.400e-01, 2.100e+00, 5.650e+00, 1.090e+00, 3.710e+00,\n        7.800e+02],\n       [1.293e+01, 3.800e+00, 2.650e+00, 1.860e+01, 1.020e+02, 2.410e+00,\n        2.410e+00, 2.500e-01, 1.980e+00, 4.500e+00, 1.030e+00, 3.520e+00,\n        7.700e+02],\n       [1.371e+01, 1.860e+00, 2.360e+00, 1.660e+01, 1.010e+02, 2.610e+00,\n        2.880e+00, 2.700e-01, 1.690e+00, 3.800e+00, 1.110e+00, 4.000e+00,\n        1.035e+03],\n       [1.285e+01, 1.600e+00, 2.520e+00, 1.780e+01, 9.500e+01, 2.480e+00,\n        2.370e+00, 2.600e-01, 1.460e+00, 3.930e+00, 1.090e+00, 3.630e+00,\n        1.015e+03],\n       [1.350e+01, 1.810e+00, 2.610e+00, 2.000e+01, 9.600e+01, 2.530e+00,\n        2.610e+00, 2.800e-01, 1.660e+00, 3.520e+00, 1.120e+00, 3.820e+00,\n        8.450e+02],\n       [1.305e+01, 2.050e+00, 3.220e+00, 2.500e+01, 1.240e+02, 2.630e+00,\n        2.680e+00, 4.700e-01, 1.920e+00, 3.580e+00, 1.130e+00, 3.200e+00,\n        8.300e+02],\n       [1.339e+01, 1.770e+00, 2.620e+00, 1.610e+01, 9.300e+01, 2.850e+00,\n        2.940e+00, 3.400e-01, 1.450e+00, 4.800e+00, 9.200e-01, 3.220e+00,\n        1.195e+03],\n       [1.330e+01, 1.720e+00, 2.140e+00, 1.700e+01, 9.400e+01, 2.400e+00,\n        2.190e+00, 2.700e-01, 1.350e+00, 3.950e+00, 1.020e+00, 2.770e+00,\n        1.285e+03],\n       [1.387e+01, 1.900e+00, 2.800e+00, 1.940e+01, 1.070e+02, 2.950e+00,\n        2.970e+00, 3.700e-01, 1.760e+00, 4.500e+00, 1.250e+00, 3.400e+00,\n        9.150e+02],\n       [1.402e+01, 1.680e+00, 2.210e+00, 1.600e+01, 9.600e+01, 2.650e+00,\n        2.330e+00, 2.600e-01, 1.980e+00, 4.700e+00, 1.040e+00, 3.590e+00,\n        1.035e+03],\n       [1.373e+01, 1.500e+00, 2.700e+00, 2.250e+01, 1.010e+02, 3.000e+00,\n        3.250e+00, 2.900e-01, 2.380e+00, 5.700e+00, 1.190e+00, 2.710e+00,\n        1.285e+03],\n       [1.358e+01, 1.660e+00, 2.360e+00, 1.910e+01, 1.060e+02, 2.860e+00,\n        3.190e+00, 2.200e-01, 1.950e+00, 6.900e+00, 1.090e+00, 2.880e+00,\n        1.515e+03],\n       [1.368e+01, 1.830e+00, 2.360e+00, 1.720e+01, 1.040e+02, 2.420e+00,\n        2.690e+00, 4.200e-01, 1.970e+00, 3.840e+00, 1.230e+00, 2.870e+00,\n        9.900e+02],\n       [1.376e+01, 1.530e+00, 2.700e+00, 1.950e+01, 1.320e+02, 2.950e+00,\n        2.740e+00, 5.000e-01, 1.350e+00, 5.400e+00, 1.250e+00, 3.000e+00,\n        1.235e+03],\n       [1.351e+01, 1.800e+00, 2.650e+00, 1.900e+01, 1.100e+02, 2.350e+00,\n        2.530e+00, 2.900e-01, 1.540e+00, 4.200e+00, 1.100e+00, 2.870e+00,\n        1.095e+03],\n       [1.348e+01, 1.810e+00, 2.410e+00, 2.050e+01, 1.000e+02, 2.700e+00,\n        2.980e+00, 2.600e-01, 1.860e+00, 5.100e+00, 1.040e+00, 3.470e+00,\n        9.200e+02],\n       [1.328e+01, 1.640e+00, 2.840e+00, 1.550e+01, 1.100e+02, 2.600e+00,\n        2.680e+00, 3.400e-01, 1.360e+00, 4.600e+00, 1.090e+00, 2.780e+00,\n        8.800e+02],\n       [1.305e+01, 1.650e+00, 2.550e+00, 1.800e+01, 9.800e+01, 2.450e+00,\n        2.430e+00, 2.900e-01, 1.440e+00, 4.250e+00, 1.120e+00, 2.510e+00,\n        1.105e+03],\n       [1.307e+01, 1.500e+00, 2.100e+00, 1.550e+01, 9.800e+01, 2.400e+00,\n        2.640e+00, 2.800e-01, 1.370e+00, 3.700e+00, 1.180e+00, 2.690e+00,\n        1.020e+03],\n       [1.422e+01, 3.990e+00, 2.510e+00, 1.320e+01, 1.280e+02, 3.000e+00,\n        3.040e+00, 2.000e-01, 2.080e+00, 5.100e+00, 8.900e-01, 3.530e+00,\n        7.600e+02],\n       [1.356e+01, 1.710e+00, 2.310e+00, 1.620e+01, 1.170e+02, 3.150e+00,\n        3.290e+00, 3.400e-01, 2.340e+00, 6.130e+00, 9.500e-01, 3.380e+00,\n        7.950e+02],\n       [1.341e+01, 3.840e+00, 2.120e+00, 1.880e+01, 9.000e+01, 2.450e+00,\n        2.680e+00, 2.700e-01, 1.480e+00, 4.280e+00, 9.100e-01, 3.000e+00,\n        1.035e+03],\n       [1.388e+01, 1.890e+00, 2.590e+00, 1.500e+01, 1.010e+02, 3.250e+00,\n        3.560e+00, 1.700e-01, 1.700e+00, 5.430e+00, 8.800e-01, 3.560e+00,\n        1.095e+03],\n       [1.324e+01, 3.980e+00, 2.290e+00, 1.750e+01, 1.030e+02, 2.640e+00,\n        2.630e+00, 3.200e-01, 1.660e+00, 4.360e+00, 8.200e-01, 3.000e+00,\n        6.800e+02],\n       [1.305e+01, 1.770e+00, 2.100e+00, 1.700e+01, 1.070e+02, 3.000e+00,\n        3.000e+00, 2.800e-01, 2.030e+00, 5.040e+00, 8.800e-01, 3.350e+00,\n        8.850e+02],\n       [1.421e+01, 4.040e+00, 2.440e+00, 1.890e+01, 1.110e+02, 2.850e+00,\n        2.650e+00, 3.000e-01, 1.250e+00, 5.240e+00, 8.700e-01, 3.330e+00,\n        1.080e+03],\n       [1.438e+01, 3.590e+00, 2.280e+00, 1.600e+01, 1.020e+02, 3.250e+00,\n        3.170e+00, 2.700e-01, 2.190e+00, 4.900e+00, 1.040e+00, 3.440e+00,\n        1.065e+03],\n       [1.390e+01, 1.680e+00, 2.120e+00, 1.600e+01, 1.010e+02, 3.100e+00,\n        3.390e+00, 2.100e-01, 2.140e+00, 6.100e+00, 9.100e-01, 3.330e+00,\n        9.850e+02],\n       [1.410e+01, 2.020e+00, 2.400e+00, 1.880e+01, 1.030e+02, 2.750e+00,\n        2.920e+00, 3.200e-01, 2.380e+00, 6.200e+00, 1.070e+00, 2.750e+00,\n        1.060e+03],\n       [1.394e+01, 1.730e+00, 2.270e+00, 1.740e+01, 1.080e+02, 2.880e+00,\n        3.540e+00, 3.200e-01, 2.080e+00, 8.900e+00, 1.120e+00, 3.100e+00,\n        1.260e+03],\n       [1.305e+01, 1.730e+00, 2.040e+00, 1.240e+01, 9.200e+01, 2.720e+00,\n        3.270e+00, 1.700e-01, 2.910e+00, 7.200e+00, 1.120e+00, 2.910e+00,\n        1.150e+03],\n       [1.383e+01, 1.650e+00, 2.600e+00, 1.720e+01, 9.400e+01, 2.450e+00,\n        2.990e+00, 2.200e-01, 2.290e+00, 5.600e+00, 1.240e+00, 3.370e+00,\n        1.265e+03],\n       [1.382e+01, 1.750e+00, 2.420e+00, 1.400e+01, 1.110e+02, 3.880e+00,\n        3.740e+00, 3.200e-01, 1.870e+00, 7.050e+00, 1.010e+00, 3.260e+00,\n        1.190e+03],\n       [1.377e+01, 1.900e+00, 2.680e+00, 1.710e+01, 1.150e+02, 3.000e+00,\n        2.790e+00, 3.900e-01, 1.680e+00, 6.300e+00, 1.130e+00, 2.930e+00,\n        1.375e+03],\n       [1.374e+01, 1.670e+00, 2.250e+00, 1.640e+01, 1.180e+02, 2.600e+00,\n        2.900e+00, 2.100e-01, 1.620e+00, 5.850e+00, 9.200e-01, 3.200e+00,\n        1.060e+03],\n       [1.356e+01, 1.730e+00, 2.460e+00, 2.050e+01, 1.160e+02, 2.960e+00,\n        2.780e+00, 2.000e-01, 2.450e+00, 6.250e+00, 9.800e-01, 3.030e+00,\n        1.120e+03],\n       [1.422e+01, 1.700e+00, 2.300e+00, 1.630e+01, 1.180e+02, 3.200e+00,\n        3.000e+00, 2.600e-01, 2.030e+00, 6.380e+00, 9.400e-01, 3.310e+00,\n        9.700e+02],\n       [1.329e+01, 1.970e+00, 2.680e+00, 1.680e+01, 1.020e+02, 3.000e+00,\n        3.230e+00, 3.100e-01, 1.660e+00, 6.000e+00, 1.070e+00, 2.840e+00,\n        1.270e+03],\n       [1.372e+01, 1.430e+00, 2.500e+00, 1.670e+01, 1.080e+02, 3.400e+00,\n        3.670e+00, 1.900e-01, 2.040e+00, 6.800e+00, 8.900e-01, 2.870e+00,\n        1.285e+03],\n       [1.237e+01, 9.400e-01, 1.360e+00, 1.060e+01, 8.800e+01, 1.980e+00,\n        5.700e-01, 2.800e-01, 4.200e-01, 1.950e+00, 1.050e+00, 1.820e+00,\n        5.200e+02]])"]}}],"execution_count":0},{"cell_type":"code","source":["for train_index, test_index in kf.split(X):\n    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n    X_train, X_test = X[train_index], X[test_index]\n    y_train, y_test = y[train_index], y[test_index]\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c5b4638d-30d6-4ab5-a077-ffa2ef83c78d"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["kf = KFold(n_splits=3)\nkf.get_n_splits(X)\n\nprint(kf)\nfor train_index, test_index in kf.split(X):\n    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n    X_train, X_test = X[train_index], X[test_index]\n    \n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e56bda16-bbcf-4d3a-843d-014ac456e916"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"KFold(n_splits=3, random_state=None, shuffle=False)\nTRAIN: [2 3 4 5] TEST: [0 1]\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["KFold(n_splits=3, random_state=None, shuffle=False)\nTRAIN: [2 3 4 5] TEST: [0 1]\n"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"\u001B[1;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)\n\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_2632/3636129290.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mtrain_index\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtest_index\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mkf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msplit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m     \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"TRAIN:\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtrain_index\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"TEST:\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtest_index\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 8\u001B[1;33m     \u001B[0mX_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mX_test\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mX\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mtrain_index\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mX\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mtest_index\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\n\u001B[1;31mTypeError\u001B[0m: unhashable type: 'numpy.ndarray'","errorSummary":"<span class='ansi-red-fg'>TypeError</span>: unhashable type: 'numpy.ndarray'","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":["\u001B[1;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)\n\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_2632/3636129290.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mtrain_index\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtest_index\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mkf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msplit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m     \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"TRAIN:\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtrain_index\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"TEST:\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtest_index\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 8\u001B[1;33m     \u001B[0mX_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mX_test\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mX\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mtrain_index\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mX\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mtest_index\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\n\u001B[1;31mTypeError\u001B[0m: unhashable type: 'numpy.ndarray'"]}}],"execution_count":0},{"cell_type":"code","source":["wine"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"324b82c3-f383-49ce-8db3-f4ac37a11bc3"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[33]: {'data': array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1.040e+00, 3.920e+00,\n         1.065e+03],\n        [1.320e+01, 1.780e+00, 2.140e+00, ..., 1.050e+00, 3.400e+00,\n         1.050e+03],\n        [1.316e+01, 2.360e+00, 2.670e+00, ..., 1.030e+00, 3.170e+00,\n         1.185e+03],\n        ...,\n        [1.327e+01, 4.280e+00, 2.260e+00, ..., 5.900e-01, 1.560e+00,\n         8.350e+02],\n        [1.317e+01, 2.590e+00, 2.370e+00, ..., 6.000e-01, 1.620e+00,\n         8.400e+02],\n        [1.413e+01, 4.100e+00, 2.740e+00, ..., 6.100e-01, 1.600e+00,\n         5.600e+02]]),\n 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n        2, 2]),\n 'frame': None,\n 'target_names': array(['class_0', 'class_1', 'class_2'], dtype='<U7'),\n 'DESCR': '.. _wine_dataset:\\n\\nWine recognition dataset\\n------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 178 (50 in each of three classes)\\n    :Number of Attributes: 13 numeric, predictive attributes and the class\\n    :Attribute Information:\\n \\t\\t- Alcohol\\n \\t\\t- Malic acid\\n \\t\\t- Ash\\n\\t\\t- Alcalinity of ash  \\n \\t\\t- Magnesium\\n\\t\\t- Total phenols\\n \\t\\t- Flavanoids\\n \\t\\t- Nonflavanoid phenols\\n \\t\\t- Proanthocyanins\\n\\t\\t- Color intensity\\n \\t\\t- Hue\\n \\t\\t- OD280/OD315 of diluted wines\\n \\t\\t- Proline\\n\\n    - class:\\n            - class_0\\n            - class_1\\n            - class_2\\n\\t\\t\\n    :Summary Statistics:\\n    \\n    ============================= ==== ===== ======= =====\\n                                   Min   Max   Mean     SD\\n    ============================= ==== ===== ======= =====\\n    Alcohol:                      11.0  14.8    13.0   0.8\\n    Malic Acid:                   0.74  5.80    2.34  1.12\\n    Ash:                          1.36  3.23    2.36  0.27\\n    Alcalinity of Ash:            10.6  30.0    19.5   3.3\\n    Magnesium:                    70.0 162.0    99.7  14.3\\n    Total Phenols:                0.98  3.88    2.29  0.63\\n    Flavanoids:                   0.34  5.08    2.03  1.00\\n    Nonflavanoid Phenols:         0.13  0.66    0.36  0.12\\n    Proanthocyanins:              0.41  3.58    1.59  0.57\\n    Colour Intensity:              1.3  13.0     5.1   2.3\\n    Hue:                          0.48  1.71    0.96  0.23\\n    OD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\\n    Proline:                       278  1680     746   315\\n    ============================= ==== ===== ======= =====\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: class_0 (59), class_1 (71), class_2 (48)\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThis is a copy of UCI ML Wine recognition datasets.\\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\\n\\nThe data is the results of a chemical analysis of wines grown in the same\\nregion in Italy by three different cultivators. There are thirteen different\\nmeasurements taken for different constituents found in the three types of\\nwine.\\n\\nOriginal Owners: \\n\\nForina, M. et al, PARVUS - \\nAn Extendible Package for Data Exploration, Classification and Correlation. \\nInstitute of Pharmaceutical and Food Analysis and Technologies,\\nVia Brigata Salerno, 16147 Genoa, Italy.\\n\\nCitation:\\n\\nLichman, M. (2013). UCI Machine Learning Repository\\n[https://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\\nSchool of Information and Computer Science. \\n\\n.. topic:: References\\n\\n  (1) S. Aeberhard, D. Coomans and O. de Vel, \\n  Comparison of Classifiers in High Dimensional Settings, \\n  Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of  \\n  Mathematics and Statistics, James Cook University of North Queensland. \\n  (Also submitted to Technometrics). \\n\\n  The data was used with many others for comparing various \\n  classifiers. The classes are separable, though only RDA \\n  has achieved 100% correct classification. \\n  (RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data)) \\n  (All results using the leave-one-out technique) \\n\\n  (2) S. Aeberhard, D. Coomans and O. de Vel, \\n  \"THE CLASSIFICATION PERFORMANCE OF RDA\" \\n  Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of \\n  Mathematics and Statistics, James Cook University of North Queensland. \\n  (Also submitted to Journal of Chemometrics).\\n',\n 'feature_names': ['alcohol',\n  'malic_acid',\n  'ash',\n  'alcalinity_of_ash',\n  'magnesium',\n  'total_phenols',\n  'flavanoids',\n  'nonflavanoid_phenols',\n  'proanthocyanins',\n  'color_intensity',\n  'hue',\n  'od280/od315_of_diluted_wines',\n  'proline']}","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[33]: {'data': array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1.040e+00, 3.920e+00,\n         1.065e+03],\n        [1.320e+01, 1.780e+00, 2.140e+00, ..., 1.050e+00, 3.400e+00,\n         1.050e+03],\n        [1.316e+01, 2.360e+00, 2.670e+00, ..., 1.030e+00, 3.170e+00,\n         1.185e+03],\n        ...,\n        [1.327e+01, 4.280e+00, 2.260e+00, ..., 5.900e-01, 1.560e+00,\n         8.350e+02],\n        [1.317e+01, 2.590e+00, 2.370e+00, ..., 6.000e-01, 1.620e+00,\n         8.400e+02],\n        [1.413e+01, 4.100e+00, 2.740e+00, ..., 6.100e-01, 1.600e+00,\n         5.600e+02]]),\n 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n        2, 2]),\n 'frame': None,\n 'target_names': array(['class_0', 'class_1', 'class_2'], dtype='<U7'),\n 'DESCR': '.. _wine_dataset:\\n\\nWine recognition dataset\\n------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 178 (50 in each of three classes)\\n    :Number of Attributes: 13 numeric, predictive attributes and the class\\n    :Attribute Information:\\n \\t\\t- Alcohol\\n \\t\\t- Malic acid\\n \\t\\t- Ash\\n\\t\\t- Alcalinity of ash  \\n \\t\\t- Magnesium\\n\\t\\t- Total phenols\\n \\t\\t- Flavanoids\\n \\t\\t- Nonflavanoid phenols\\n \\t\\t- Proanthocyanins\\n\\t\\t- Color intensity\\n \\t\\t- Hue\\n \\t\\t- OD280/OD315 of diluted wines\\n \\t\\t- Proline\\n\\n    - class:\\n            - class_0\\n            - class_1\\n            - class_2\\n\\t\\t\\n    :Summary Statistics:\\n    \\n    ============================= ==== ===== ======= =====\\n                                   Min   Max   Mean     SD\\n    ============================= ==== ===== ======= =====\\n    Alcohol:                      11.0  14.8    13.0   0.8\\n    Malic Acid:                   0.74  5.80    2.34  1.12\\n    Ash:                          1.36  3.23    2.36  0.27\\n    Alcalinity of Ash:            10.6  30.0    19.5   3.3\\n    Magnesium:                    70.0 162.0    99.7  14.3\\n    Total Phenols:                0.98  3.88    2.29  0.63\\n    Flavanoids:                   0.34  5.08    2.03  1.00\\n    Nonflavanoid Phenols:         0.13  0.66    0.36  0.12\\n    Proanthocyanins:              0.41  3.58    1.59  0.57\\n    Colour Intensity:              1.3  13.0     5.1   2.3\\n    Hue:                          0.48  1.71    0.96  0.23\\n    OD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\\n    Proline:                       278  1680     746   315\\n    ============================= ==== ===== ======= =====\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: class_0 (59), class_1 (71), class_2 (48)\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThis is a copy of UCI ML Wine recognition datasets.\\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\\n\\nThe data is the results of a chemical analysis of wines grown in the same\\nregion in Italy by three different cultivators. There are thirteen different\\nmeasurements taken for different constituents found in the three types of\\nwine.\\n\\nOriginal Owners: \\n\\nForina, M. et al, PARVUS - \\nAn Extendible Package for Data Exploration, Classification and Correlation. \\nInstitute of Pharmaceutical and Food Analysis and Technologies,\\nVia Brigata Salerno, 16147 Genoa, Italy.\\n\\nCitation:\\n\\nLichman, M. (2013). UCI Machine Learning Repository\\n[https://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\\nSchool of Information and Computer Science. \\n\\n.. topic:: References\\n\\n  (1) S. Aeberhard, D. Coomans and O. de Vel, \\n  Comparison of Classifiers in High Dimensional Settings, \\n  Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of  \\n  Mathematics and Statistics, James Cook University of North Queensland. \\n  (Also submitted to Technometrics). \\n\\n  The data was used with many others for comparing various \\n  classifiers. The classes are separable, though only RDA \\n  has achieved 100% correct classification. \\n  (RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data)) \\n  (All results using the leave-one-out technique) \\n\\n  (2) S. Aeberhard, D. Coomans and O. de Vel, \\n  \"THE CLASSIFICATION PERFORMANCE OF RDA\" \\n  Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of \\n  Mathematics and Statistics, James Cook University of North Queensland. \\n  (Also submitted to Journal of Chemometrics).\\n',\n 'feature_names': ['alcohol',\n  'malic_acid',\n  'ash',\n  'alcalinity_of_ash',\n  'magnesium',\n  'total_phenols',\n  'flavanoids',\n  'nonflavanoid_phenols',\n  'proanthocyanins',\n  'color_intensity',\n  'hue',\n  'od280/od315_of_diluted_wines',\n  'proline']}"]}}],"execution_count":0},{"cell_type":"code","source":["splits = 3\nkf = KFold(n_splits=splits)\nX = np.arange(0,12,1)\nprint(len(X)//splits)\n\nfor fold_nb, (train_index,test_index) in enumerate(kf.split(X)):\n    print(\"Fold no:\", fold_nb)\n    print(\"train size:\", len(train_index),\"test size:\",len(test_index))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"440784bd-7783-4a51-9bc8-e424e8484b00"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"4\nFold no: 0\ntrain size: 8 test size: 4\nFold no: 1\ntrain size: 8 test size: 4\nFold no: 2\ntrain size: 8 test size: 4\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["4\nFold no: 0\ntrain size: 8 test size: 4\nFold no: 1\ntrain size: 8 test size: 4\nFold no: 2\ntrain size: 8 test size: 4\n"]}}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8765d4e2-dd3c-4f03-84f9-1505b9c76e81"}},"outputs":[],"execution_count":0}],"metadata":{"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"version":"3.8.12","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3.8.12 ('Machine_learning')","language":"python","name":"python3"},"orig_nbformat":4,"application/vnd.databricks.v1+notebook":{"notebookName":"zad3","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":3695620111988127},"interpreter":{"hash":"458921dbe1c9b1116488aece82fc8183a35eb51f0a7aeffeb773918d1e5fa3cb"}},"nbformat":4,"nbformat_minor":0}
